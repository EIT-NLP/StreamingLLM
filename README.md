<h1 align="center"><b>Repository of Streaming Large Language Models</b></h1>
</div>




## 1. TL;DR
This repository includes a family of streaming large language models.

## 2. What are streaming LLMs?
Streaming LLMs refer to large language models that support both the progressive processing of incoming information (streaming input) and the step-by-step generation of outputs (streaming output). Building upon this foundation, we further focus on scenarios where the model performs streaming input and output simultaneously. 

Here is an example for text-to-text streaming：
![streaming-processing](./assets/streaming.gif)

Here is an example for speech-to-text streaming：
[![Watch the video](./assets/StreamingASR.gif)](./assets/StreamingASR.mp4)





## 3. Content
* [ACL 2025 Findings] [LLM as Effective Streaming Processor: Bridging Streaming-Batch Mismatches with Group Position Encoding.](./StreamingLLM_GPE/README.md)
* [ICLR 2026] [StreamingThinker: Large Language Models Can Think While Reading.](./StreamingThinker/README.md)
* [arxiv preprint] [Speak While Watching: Unleashing TRUE Real-Time Video Understanding Capability of Multimodal Large Language Models.](https://github.com/EIT-NLP/Speak-While-Watching)



## Contact
If you have any questions, please contact: jl-tong@sjtu.edu.cn
